{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTBwlGQaWFsC4BoHiAHBJg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaraKmair/How-to/blob/master/Pyspark%20on%20Google%20colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Running Pyspark in Colab**\n"
      ],
      "metadata": {
        "id": "7yN8rDMJzbf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check python version \n",
        "!python --version "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55L5m3YJX64T",
        "outputId": "43488a62-5c50-4fa4-c342-f293668489cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the directory \n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhCF9exeXGI7",
        "outputId": "a3594279-4a69-4e46-b8b2-e3336f41f967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove file and list existing files in the directory \n",
        "!rm spark-3.0.0-bin-hadoop3.2\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOKqHJ3oaq70",
        "outputId": "1f76ebc1-386c-4071-f76d-d0ad42ebcafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'spark-3.0.0-bin-hadoop3.2': Is a directory\n",
            "sample_data  spark-3.0.0-bin-hadoop3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download pyspark \n",
        "# !wget https://dlcdn.apache.org/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz \n",
        "\n",
        "# Install java\n",
        "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Install spark (change the version number if needed)\n",
        "!wget https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CVTIXBSXGMM",
        "outputId": "22e0806c-16dd-4cd6-d0e9-aeeff09be230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-10 19:21:36--  https://dlcdn.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
            "Resolving dlcdn.apache.org (dlcdn.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
            "Connecting to dlcdn.apache.org (dlcdn.apache.org)|151.101.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 300965906 (287M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.2.0-bin-hadoop3.2.tgz’\n",
            "\n",
            "spark-3.2.0-bin-had 100%[===================>] 287.02M   248MB/s    in 1.2s    \n",
            "\n",
            "2022-01-10 19:21:37 (248 MB/s) - ‘spark-3.2.0-bin-hadoop3.2.tgz’ saved [300965906/300965906]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "mvUYXxeuaOMP",
        "outputId": "e5d1e6c4-e0a0-49a7-adcf-17ad3f447a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  spark-3.0.0-bin-hadoop3.2\tspark-3.2.0-bin-hadoop3.2.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwmHaEb8XGUS",
        "outputId": "66df4b8f-1749-4a2f-fbb7-df999b8b0b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-3.0.0-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if it's downloaded \n",
        "!ls /content/spark-3.0.0-bin-hadoop3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csDiI4VmXGWt",
        "outputId": "97e0a086-13e6-430c-c830-9c03170a1b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin   data\tjars\t    LICENSE   NOTICE  R\t\t RELEASE  yarn\n",
            "conf  examples\tkubernetes  licenses  python  README.md  sbin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "id": "a6hcE8HSXGYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8187c653-9deb-4813-f070-56f85643c73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-1.4.2-py2.py3-none-any.whl (4.2 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-1.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#point it to the right directory \n",
        "import os\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "#findspark to make pyspark readable \n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "juwKzYFTXGaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "mrr_eseKXGcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q91Mo5kP6MVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}